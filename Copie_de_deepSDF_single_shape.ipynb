{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copie de deepSDF_single_shape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lyspal/MCS-IFT6113-Final-Project-DeepSDF/blob/deepsdf-single/Copie_de_deepSDF_single_shape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-f4-qRIFeOn"
      },
      "source": [
        "# author: Sylvain Laporte\n",
        "# program: deepSDF_single_shape.py\n",
        "# date: 2020-12-08\n",
        "# object: Implementation of single-shape DeepSDF\n",
        "\n",
        "# The PyTorch code structure used in this project is adapted from the tutorial \"PyTorch: Zero to GANs\" by Aakash N.S. for freeCodeCamp.org\n",
        "# This tutorial is available at https://jovian.ai/aakashns/01-pytorch-basics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ID8J6TFeOn"
      },
      "source": [
        "# Deep SDF - Single shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8BedeefFeOn"
      },
      "source": [
        "# # FOR COLAB. Installing packages\n",
        "# !setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSrF28xgFeOo"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "# import trimesh\n",
        "# import pyrender"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO95a70GFeOo"
      },
      "source": [
        "## Preprocessing data\n",
        "\n",
        "We need to sample 500 000 spatial points from a mesh and compute their corresponding SDF values. We sample more aggressively near the surface of the mesh."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEYhkJ5iFeOo"
      },
      "source": [
        "### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9vClpBkFeOo"
      },
      "source": [
        "# Run from command line tool"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XzAblIaFeOo"
      },
      "source": [
        "### Using already preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCiF8djJFeOo"
      },
      "source": [
        "import json\n",
        "\n",
        "# Load preprocessed dataset\n",
        "dataset_file = \"cube-samples.json\"\n",
        "\n",
        "points = None\n",
        "sdfs = None\n",
        "\n",
        "with open(dataset_file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "    points = torch.tensor(data['points'])\n",
        "    sdfs = data['sdfs']\n",
        "\n",
        "# Convert to a workable list of tuples\n",
        "dataset = list(zip(points, sdfs))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv4vuz0NJlHd",
        "outputId": "18b56940-8639-4372-9b58-ae153202a4a4"
      },
      "source": [
        "type(dataset[0][0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "wp2ypgIoFeOo"
      },
      "source": [
        "### Split dataset in batches\n",
        "\n",
        "#### Split in trainning dataset and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FboArLPtFeOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76333b26-0fa3-46da-c0c9-e18c23d724fb"
      },
      "source": [
        "validation_size = 10000\n",
        "train_size = len(dataset) - validation_size\n",
        "\n",
        "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
        "len(train_dataset), len(validation_dataset)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2eiRY0YFeOo"
      },
      "source": [
        "#### Create batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BKpxHhBFeOo"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(validation_dataset, batch_size*2, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpuX0UYcFeOo"
      },
      "source": [
        "## Preparing for running on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5qc9R_LFeOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a118eae8-b4d1-45b9-e451-514c8510413e"
      },
      "source": [
        "# Check if a CUDA GPU is available\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihE9EFc2FeOo"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Helper function to select the device on which to run the model\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtT6U63nFeOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f75014-ca9f-420b-cb4d-b1d05a9d4323"
      },
      "source": [
        "# Set and check the default device\n",
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTFxQnYFeOo"
      },
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Helper function to move the data to the chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G81TV_lZFeOo"
      },
      "source": [
        "class DeviceDataLoader():\n",
        "    \"\"\"Dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BznqtnK1FeOo"
      },
      "source": [
        "### Load dataset to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t83ae1glFeOo"
      },
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aESEXvAtFeOp"
      },
      "source": [
        "## Training the neural network $f_\\theta$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z3Du39YFeOp"
      },
      "source": [
        "### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KmTxtNbFeOp"
      },
      "source": [
        "loss_function = nn.L1Loss()\n",
        "\n",
        "# def clamp(f_theta, delta):\n",
        "#     max_f_theta = torch.max(f_theta)\n",
        "#     max_op = max(-delta, max_f_theta)\n",
        "\n",
        "#     return min(delta, max_op)\n",
        "\n",
        "# def loss_func(f_theta, s):\n",
        "#     delta = 0.1     # parameter that controls the distance from the surface\n",
        "#     return abs(clamp(f_theta, delta) - clamp(s, delta))"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3YJi7AvFeOp"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5MIsq1UFeOp"
      },
      "source": [
        "#### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4cmAn0mFeOp"
      },
      "source": [
        "def accuracy(outputs, sdf_values):\n",
        "    \"\"\"For human validation only\"\"\"\n",
        "    pass"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkxym4VhFeOp"
      },
      "source": [
        "class DeepSDF_single(nn.Module):\n",
        "    \"\"\"Multi-layer fully-connected feed-forward neural network with 8 layers, each applied with dropout\"\"\"\n",
        "    def __init__(self, in_size, hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        # Hidden layer 1\n",
        "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
        "        # Hidden layer 2\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 3\n",
        "        self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 4\n",
        "        self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 5\n",
        "        self.linear5 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 6\n",
        "        self.linear6 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 7\n",
        "        self.linear7 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Output layer\n",
        "        self.linear8 = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.linear1(xb)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear3(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear4(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear5(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear6(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear7(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear8(out)\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        point_samples, sdf_values = batch\n",
        "        out = self(point_samples)       # generate predictions\n",
        "        loss = loss_function(out, sdf_values)    # compute loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        point_samples, sdf_values = batch\n",
        "        out = self(point_samples)           # generate predictions\n",
        "        loss = loss_function(out, sdf_values)        # compute loss\n",
        "        acc = accuracy(out, sdf_values)     # compute accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "\n",
        "        # batch_accs = [x['val_acc'] for x in outputs]\n",
        "        # epoch_acc = torch.stack(batch_accs).mean()      # combine accuracies\n",
        "        # return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch, result['val_loss'],))\n",
        "        # print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7lYjCwFFeOp"
      },
      "source": [
        "#### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv2c8PQpFeOp"
      },
      "source": [
        "input_size = 3\n",
        "hidden_size = 512\n",
        "out_size = 1\n",
        "\n",
        "model = DeepSDF_single(input_size, hidden_size=hidden_size, out_size=out_size)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxnG99JBFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0dd27d-84bd-4505-e8a7-94f4265e2238"
      },
      "source": [
        "# Check the parameters for each layers\n",
        "for t in model.parameters():\n",
        "    print(t.shape)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([512, 3])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 512])\n",
            "torch.Size([512])\n",
            "torch.Size([1, 512])\n",
            "torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xauDofQoFeOp"
      },
      "source": [
        "#### Load the model on the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxdWv0VMFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e392c5-6e9d-4110-93d7-a671f83f2163"
      },
      "source": [
        "to_device(model, device)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepSDF_single(\n",
              "  (linear1): Linear(in_features=3, out_features=512, bias=True)\n",
              "  (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear3): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear4): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear5): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear6): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear7): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear8): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zoj4SQnJFeOp"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4-Zsh28FeOp"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmp4MpJRFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458e4c86-b5eb-4181-cb09-f7506e652c68"
      },
      "source": [
        "# Checking the accuracy of the untrained model\n",
        "history = [evaluate(model, val_loader)]\n",
        "history"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:94: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:94: UserWarning: Using a target size (torch.Size([272])) that is different to the input size (torch.Size([272, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_loss': 0.06143866396811562}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSIbO7CqFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5c7e25-c4b5-47d6-80bf-660bda8e7c08"
      },
      "source": [
        "epochs = 5\n",
        "learning_rate = 0.5\n",
        "\n",
        "print(model.parameters)\n",
        "\n",
        "# Train the model\n",
        "history += fit(epochs, learning_rate, model, train_loader, val_loader)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.parameters of DeepSDF_single(\n",
            "  (linear1): Linear(in_features=3, out_features=512, bias=True)\n",
            "  (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear3): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear4): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear5): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear6): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear7): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear8): Linear(in_features=512, out_features=1, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:94: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:94: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 1.1121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:94: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:94: UserWarning: Using a target size (torch.Size([272])) that is different to the input size (torch.Size([272, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1], val_loss: 0.4830\n",
            "Epoch [2], val_loss: 0.5879\n",
            "Epoch [3], val_loss: 0.3970\n",
            "Epoch [4], val_loss: 0.4194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga0K_BFbFeOp"
      },
      "source": [
        "### Plot the losses and accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1EmwL4bFeOp"
      },
      "source": [
        "# Plot the losses\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c9Nke4CFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "74fb9375-2752-414e-efdf-0b3fb7298120"
      },
      "source": [
        "losses = [x['val_loss'] for x in history]\n",
        "plt.plot(losses, '-x')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss vs. No. of epochs')\n",
        "\n",
        "# accuracies = [x['val_acc'] for x in history]\n",
        "# plt.plot(accuracies, '-x')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.title('Accuracy vs. No. of epochs')"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs. No. of epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8sJeos5FeOp"
      },
      "source": [
        "## Render implicit surface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE1WIDqeFeOp"
      },
      "source": [
        "### Get the mesh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIpOnKDkFeOp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEd5WTcQFeOp"
      },
      "source": [
        "### Render the mesh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIdYFiD0FeOp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}