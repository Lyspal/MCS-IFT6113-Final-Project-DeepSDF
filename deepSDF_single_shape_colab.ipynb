{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "Copie de deepSDF_single_shape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lyspal/MCS-IFT6113-Final-Project-DeepSDF/blob/deepsdf-single/Copie_de_deepSDF_single_shape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-f4-qRIFeOn"
      },
      "source": [
        "# author: Sylvain Laporte\n",
        "# program: deepSDF_single_shape.py\n",
        "# date: 2020-12-08\n",
        "# object: Implementation of single-shape DeepSDF\n",
        "\n",
        "# The PyTorch code structure used in this project is adapted from the tutorial \"PyTorch: Zero to GANs\" by Aakash N.S. for freeCodeCamp.org\n",
        "# This tutorial is available at https://jovian.ai/aakashns/01-pytorch-basics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ID8J6TFeOn"
      },
      "source": [
        "# Deep SDF - Single shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8BedeefFeOn"
      },
      "source": [
        "# Unused. Preprocessing moved to local machine. \n",
        "# # FOR COLAB. Installing packages.\n",
        "# !setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSrF28xgFeOo"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "# import trimesh\n",
        "# import pyrender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO95a70GFeOo"
      },
      "source": [
        "## Preprocessing data\n",
        "\n",
        "We need to sample 500 000 spatial points from a mesh and compute their corresponding SDF values. We sample more aggressively near the surface of the mesh.\n",
        "\n",
        "We used 250 000 points instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEYhkJ5iFeOo"
      },
      "source": [
        "### Preprocess the data\n",
        "\n",
        "Run locally with from command line tool `preprocessing_data.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XzAblIaFeOo"
      },
      "source": [
        "### Using already preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCiF8djJFeOo"
      },
      "source": [
        "import json\n",
        "\n",
        "# Load preprocessed dataset\n",
        "dataset_file = \"cube-samples.json\"\n",
        "\n",
        "points = None\n",
        "sdfs = None\n",
        "\n",
        "with open(dataset_file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "    points = torch.tensor(data['points'])\n",
        "    sdfs = data['sdfs']\n",
        "\n",
        "# Convert to a workable list of tuples\n",
        "dataset = list(zip(points, sdfs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv4vuz0NJlHd",
        "outputId": "18b56940-8639-4372-9b58-ae153202a4a4"
      },
      "source": [
        "type(dataset[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "wp2ypgIoFeOo"
      },
      "source": [
        "### Split dataset in batches\n",
        "\n",
        "#### Split in trainning dataset and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FboArLPtFeOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76333b26-0fa3-46da-c0c9-e18c23d724fb"
      },
      "source": [
        "validation_size = 10000\n",
        "train_size = len(dataset) - validation_size\n",
        "\n",
        "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
        "len(train_dataset), len(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2eiRY0YFeOo"
      },
      "source": [
        "#### Create batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BKpxHhBFeOo"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(validation_dataset, batch_size*2, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpuX0UYcFeOo"
      },
      "source": [
        "## Preparing for running on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5qc9R_LFeOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a118eae8-b4d1-45b9-e451-514c8510413e"
      },
      "source": [
        "# Check if a CUDA GPU is available\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihE9EFc2FeOo"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Helper function to select the device on which to run the model\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtT6U63nFeOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f75014-ca9f-420b-cb4d-b1d05a9d4323"
      },
      "source": [
        "# Set and check the default device\n",
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTFxQnYFeOo"
      },
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Helper function to move the data to the chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G81TV_lZFeOo"
      },
      "source": [
        "class DeviceDataLoader():\n",
        "    \"\"\"Dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BznqtnK1FeOo"
      },
      "source": [
        "### Load dataset to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t83ae1glFeOo"
      },
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aESEXvAtFeOp"
      },
      "source": [
        "## Training the neural network $f_\\theta$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z3Du39YFeOp"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "We used built-in L1 loss function instead of our own implementation. The latter couldn't be derived."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KmTxtNbFeOp"
      },
      "source": [
        "loss_function = nn.L1Loss()\n",
        "\n",
        "# def clamp(f_theta, delta):\n",
        "#     max_f_theta = torch.max(f_theta)\n",
        "#     max_op = max(-delta, max_f_theta)\n",
        "\n",
        "#     return min(delta, max_op)\n",
        "\n",
        "# def loss_func(f_theta, s):\n",
        "#     delta = 0.1     # parameter that controls the distance from the surface\n",
        "#     return abs(clamp(f_theta, delta) - clamp(s, delta))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3YJi7AvFeOp"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5MIsq1UFeOp"
      },
      "source": [
        "#### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4cmAn0mFeOp"
      },
      "source": [
        "def accuracy(outputs, sdf_values):\n",
        "    \"\"\"For human validation only\"\"\"\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkxym4VhFeOp"
      },
      "source": [
        "class DeepSDF_single(nn.Module):\n",
        "    \"\"\"Multi-layer fully-connected feed-forward neural network with 8 layers, each applied with dropout\"\"\"\n",
        "    def __init__(self, in_size, hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        # Hidden layer 1\n",
        "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
        "        # Hidden layer 2\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 3\n",
        "        self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 4\n",
        "        self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 5\n",
        "        self.linear5 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 6\n",
        "        self.linear6 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Hidden layer 7\n",
        "        self.linear7 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Output layer\n",
        "        self.linear8 = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.linear1(xb)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear3(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear4(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear5(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear6(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear7(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear8(out)\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        point_samples, sdf_values = batch\n",
        "        out = self(point_samples)       # generate predictions\n",
        "        loss = loss_function(out, sdf_values)    # compute loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        point_samples, sdf_values = batch\n",
        "        out = self(point_samples)           # generate predictions\n",
        "        loss = loss_function(out, sdf_values)        # compute loss\n",
        "        acc = accuracy(out, sdf_values)     # compute accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "\n",
        "        # batch_accs = [x['val_acc'] for x in outputs]\n",
        "        # epoch_acc = torch.stack(batch_accs).mean()      # combine accuracies\n",
        "        # return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch, result['val_loss'],))\n",
        "        # print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7lYjCwFFeOp"
      },
      "source": [
        "#### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv2c8PQpFeOp"
      },
      "source": [
        "input_size = 3\n",
        "hidden_size = 512\n",
        "out_size = 1\n",
        "\n",
        "model = DeepSDF_single(input_size, hidden_size=hidden_size, out_size=out_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxnG99JBFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0dd27d-84bd-4505-e8a7-94f4265e2238"
      },
      "source": [
        "# Check the parameters for each layers\n",
        "for t in model.parameters():\n",
        "    print(t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xauDofQoFeOp"
      },
      "source": [
        "#### Load the model on the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxdWv0VMFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e392c5-6e9d-4110-93d7-a671f83f2163"
      },
      "source": [
        "to_device(model, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zoj4SQnJFeOp"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4-Zsh28FeOp"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmp4MpJRFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458e4c86-b5eb-4181-cb09-f7506e652c68"
      },
      "source": [
        "# Checking the accuracy of the untrained model\n",
        "history = [evaluate(model, val_loader)]\n",
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSIbO7CqFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5c7e25-c4b5-47d6-80bf-660bda8e7c08"
      },
      "source": [
        "epochs = 5\n",
        "learning_rate = 0.5\n",
        "\n",
        "print(model.parameters)\n",
        "\n",
        "# Train the model\n",
        "history += fit(epochs, learning_rate, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga0K_BFbFeOp"
      },
      "source": [
        "### Plot the losses and accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1EmwL4bFeOp"
      },
      "source": [
        "# Plot the losses\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c9Nke4CFeOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "74fb9375-2752-414e-efdf-0b3fb7298120"
      },
      "source": [
        "losses = [x['val_loss'] for x in history]\n",
        "plt.plot(losses, '-x')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss vs. No. of epochs')\n",
        "\n",
        "# accuracies = [x['val_acc'] for x in history]\n",
        "# plt.plot(accuracies, '-x')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.title('Accuracy vs. No. of epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Save the trained model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"cube\"\n",
        "\n",
        "PATH = f\"{MODEL_NAME}-model.pt\"\n",
        "\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8sJeos5FeOp"
      },
      "source": [
        "## Render implicit surface\n",
        "\n",
        "This step is done locally using `reconstruct_mesh_from_model.py`"
      ]
    },
    {
      "source": [
        "### Get SDF volume field"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE1WIDqeFeOp"
      },
      "source": [
        "### Get the mesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEd5WTcQFeOp"
      },
      "source": [
        "### Render the mesh"
      ]
    }
  ]
}